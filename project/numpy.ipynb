{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Numpy",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Импорт библиотеки",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 1. Получить датасет Ирис",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n#iris = np.genfromtxt(url, delimiter=\",\", dtype=str)\niris = np.genfromtxt('iris.csv', delimiter=',', dtype=float, skip_header=1)\nprint(iris[:10])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 2. Представить датасет одномерный/двумерный массивы (признаки поместить в матрицу (n, 4), названия самого ириса --- вектор размера n). Отобразить сколько места он занимает",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "features = iris[:, :4].astype(float)\nnames = iris[:, 4]\nprint(\"Размер матрицы признаков = \", features.shape)\nprint(\"Размер вектора названий = \", names.shape)\nprint(f\"Матрица признаков занимает {features.nbytes} байт\")\nprint(f\"Вектор названий ириса занимает {names.nbytes} байт\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 3. Нормализовать данные на промежуток от 0 до 1 для каждой колонки",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "f_min = features.min(axis=0)\nf_max = features.max(axis=0)\nf_normal = (features - f_min) / (f_max - f_min)\nprint(f\"Матрица признаков\\n{f_normal[:5]}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 4. Представить один из признаков в виде категориальной переменной и разделить её на три типа используя квантили.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "f1 = f_normal[:, 0]\nquantiles = np.quantile(f1, [0.25, 0.75])\ncategories = np.where(f1 < quantiles[0], 'small',\n                      np.where(f1 <= quantiles[1], 'medium', 'big'))\n\nprint(categories[:10])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 5. Разделить датасет на две случайные выборки (0.8 / 0.2)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "np.random.seed(42)\nindices = np.random.permutation(len(f_normal))\nsplit_index = int(len(f_normal) * 0.8)\n\nf_train = f_normal[indices[:split_index]]\nnames_train = names[indices[:split_index]]\n\nf_test = f_normal[indices[split_index:]]\nnames_test = names[indices[split_index:]]\n\nprint(f'Длина тренировочной датасета: {names_train.shape[0]}')\nprint(f'Длина тестового датасета: {names_test.shape[0]}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 6. Выбрать один из методов классификации (к примеру, SVC), обучить на тренировочном датасете, оценить результат на тестовом и сделать выводы",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Импорт библиотек",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Обучение",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "model = SVC()\nmodel.fit(f_train, names_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Оценка",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "names_predict = model.predict(f_test)\naccuracy = accuracy_score(names_test, names_predict)\nprint(f\"Точность модели: {accuracy}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Вывод\nТочность равна почти 97%. Следовательно, можно сказать, что модель хорошо обучилась, её можно использовать.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 7. Проведите три эксперимента изменяя гиперпараметры модели или условия препроцессинга данных (например, нормализованные или нет данные), сделайте выводы",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### **Эксперимент 1.** Изменение параметра регуляризации C",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "models = {\n    'C=0.01': SVC(C=0.01),\n    'C=1.0': SVC(C=1.0),\n    'C=10.0': SVC(C=10.0)\n}\n\nresults = {}\nfor name, clf in models.items():\n    clf.fit(f_train, names_train)\n    names_predict = clf.predict(f_test)\n    results[name] = accuracy_score(names_test, names_predict)\n\nprint(results)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Вывод\nИзменение параметра C приводит к изменению точности модели в ту же сторону.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### **Эксперимент 2.** Использование ненормализованных данных",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "f_train_orig = f_train * (f_max - f_min) + f_min\nf_test_orig = f_test * (f_max - f_min) + f_min\n\nmodel_orig = SVC()\nmodel_orig.fit(f_train_orig, names_train)\n\nnames_predict_orig = model_orig.predict(f_test_orig)\n\naccuracy_orig = accuracy_score(names_test, names_predict_orig)\nprint(accuracy_orig)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Вывод\nТочность модели не меняется. Это значит, что нормализация не влияет на неё.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### **Эксперимент 3.** Использование другого метода классификации (K-ближайших соседей (KNN))",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\n\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(f_train, names_train)\n\nnames_predict_knn = knn_model.predict(f_test)\naccuracy_knn = accuracy_score(names_test, names_predict_knn)\n\nprint(f\"Точность модели KNN: {accuracy_knn}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Вывод\nИспользование разных методов классификации может привести к различным результатам.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 8. Пользуясь методами уменьшения размерности (PCA, t-sne) визуализировать датасет",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Импорт библиотек",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Создание графика",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def create_plot(data, labels, title):\n    fig, ax = plt.subplots(figsize=(5, 5))\n    colors = ['blue', 'green', 'red']\n    for label, color in zip(np.unique(labels), colors):\n        idx = np.where(labels == label)[0]\n        ax.scatter(data[idx, 0], data[idx, 1], c=color, label=label)\n    ax.legend()\n    ax.set_title(title)\n    plt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "*   PCA",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pca = PCA(n_components=2)\nf_pca = pca.fit_transform(f_normal)\n\ncreate_plot(f_pca, names, 'PCA: Оригинальные данные')\nnames_pred = model.predict(f_normal)\ncreate_plot(f_pca, names_predict, 'PCA: Предсказательные данные')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "*   t-sne",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tsne = TSNE(n_components=2, random_state=42)\nf_tsne = tsne.fit_transform(f_normal)\n\ncreate_plot(f_tsne, names, 't-SNE: Оригинальные данные')\ncreate_plot(f_tsne, names_predict, 't-SNE: Предсказательные данные')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
